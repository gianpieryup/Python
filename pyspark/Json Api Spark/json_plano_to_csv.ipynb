{"cells":[{"cell_type":"markdown","metadata":{},"source":["## JSON Plano to CSV in Spark\n","\n","Nos llego un archivo json en texto plano (es decir todo en una sola linea) y deseamos convertirlo en un csv"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Apache Spark Version :3.3.1\n"]}],"source":["import findspark\n","findspark.init()\n","\n","# Creamos la session de Spark\n","import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import *\n","\n","spark = SparkSession.builder.getOrCreate()\n","print('Apache Spark Version :' + spark.sparkContext.version)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["df_json = spark.read.text(\"filejsonplano.csv\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+\n","|               value|\n","+--------------------+\n","|{\"records\":[{\"id\"...|\n","+--------------------+\n","\n"]}],"source":["df_json.show()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["json_schema =   StructType([\n","                StructField('records',  \n","                    ArrayType(StructType([\n","                        StructField('id',  StringType(), True ),\n","                        StructField('first_name', StringType(), True),\n","                        StructField('last_name', StringType(), True),\n","                        StructField('email', StringType(), True),\n","                        StructField('gender', StringType(), True),\n","                        StructField('ip_address', StringType(), True)\n","                    ])),\n","                True )])"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- records: array (nullable = true)\n"," |    |-- element: struct (containsNull = true)\n"," |    |    |-- id: string (nullable = true)\n"," |    |    |-- first_name: string (nullable = true)\n"," |    |    |-- last_name: string (nullable = true)\n"," |    |    |-- email: string (nullable = true)\n"," |    |    |-- gender: string (nullable = true)\n"," |    |    |-- ip_address: string (nullable = true)\n","\n"]}],"source":["df_details = df_json.withColumn(\"parsed_data\", from_json(df_json[\"value\"], json_schema)).drop(\"value\")\n","    #Bajamas un nivel para no hacer 'parsed_data.columna'\n","df = df_details.select(col(\"parsed_data.*\"))\n","df.printSchema()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["df = df.withColumn(\"rec_exp\", explode_outer(\"records\"))\n","df_final = df.select(col('rec_exp.*'))"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+---------+--------------------+------+--------------+\n","| id|first_name|last_name|               email|gender|    ip_address|\n","+---+----------+---------+--------------------+------+--------------+\n","|  1|  Jeanette|Penddreth|jpenddreth0@censu...|Female|   26.58.193.2|\n","|  2|   Giavani| Frediani|gfrediani1@senate...|  Male| 229.179.4.212|\n","|  3|     Noell|      Bea| nbea2@imageshack.us|Female|180.66.162.255|\n","|  4|   Willard|    Valek|      wvalek3@vk.com|  Male|  67.76.188.26|\n","+---+----------+---------+--------------------+------+--------------+\n","\n","root\n"," |-- id: string (nullable = true)\n"," |-- first_name: string (nullable = true)\n"," |-- last_name: string (nullable = true)\n"," |-- email: string (nullable = true)\n"," |-- gender: string (nullable = true)\n"," |-- ip_address: string (nullable = true)\n","\n"]}],"source":["df_final.show()\n","df_final.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["## Save Data\n","\n","### Opcion 1\n","\n","Si el marco de datos cabe en la **memoria del controlado**r y desea guardarlo en el **sistema de archivos local**, \n","puede convertir **Spark DataFrame** a **Pandas DataFrame local** usando `toPandas()` el m√©todo y luego simplemente usar `to_csv()`"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["df_final.toPandas().to_csv('mycsvtoPandas.csv', sep='|', header=False, index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Opcion 2\n","\n","Si deseas guardarlo en un **HDFS** como por ejemplo **Amazon S3**\n","\n","Recordar que esto genera un folder llamdo `path/` con un archivo csv dentro, con un nombre raro. A partir de aqui bajarlo a mano o usar  funciones de movimiento, renombrar, borrar archivos o folders en su HDFS\n","\n","```shell\n","path/\n"," |--  SUSCESS\n"," |--  part-010233110193.csv\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_final.repartition(1).write.csv(\"path\", sep='|')"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":2}
